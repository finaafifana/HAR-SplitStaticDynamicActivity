{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAR STATIC DYNAMIC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAH6qsc7xdIV"
      },
      "source": [
        "from numpy import mean\r\n",
        "from numpy import std\r\n",
        "from numpy import dstack\r\n",
        "import pandas as pd\r\n",
        "from matplotlib import pyplot\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers.convolutional import Conv2D\r\n",
        "from keras.layers.convolutional import MaxPooling2D\r\n",
        "from keras.layers.convolutional import Conv1D\r\n",
        "from keras.layers.convolutional import MaxPooling1D\r\n",
        "from keras.utils import to_categorical\r\n",
        "import seaborn as sns\r\n",
        "import numpy as np\r\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD-Iiod8oJBT"
      },
      "source": [
        "import pandas as pd\r\n",
        "import zipfile\r\n",
        "from sklearn.utils import shuffle\r\n",
        "\r\n",
        "zf = zipfile.ZipFile('drive/My Drive/SOURCE DATA SCIENCE/archive.zip') # having archive.csv zipped file.\r\n",
        "df_train = pd.read_csv(zf.open('train.csv'), index_col = \"Activity\") \r\n",
        "df_test = pd.read_csv(zf.open('test.csv'), index_col = \"Activity\")\r\n",
        "\r\n",
        "df_train = shuffle(df_train)\r\n",
        "df_test = shuffle(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "NNoR0rEZYl0h",
        "outputId": "39fc3b8b-1e84-4fed-cc61-35a9218ca7b8"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tBodyAcc-mean()-X</th>\n",
              "      <th>tBodyAcc-mean()-Y</th>\n",
              "      <th>tBodyAcc-mean()-Z</th>\n",
              "      <th>tBodyAcc-std()-X</th>\n",
              "      <th>tBodyAcc-std()-Y</th>\n",
              "      <th>tBodyAcc-std()-Z</th>\n",
              "      <th>tBodyAcc-mad()-X</th>\n",
              "      <th>tBodyAcc-mad()-Y</th>\n",
              "      <th>tBodyAcc-mad()-Z</th>\n",
              "      <th>tBodyAcc-max()-X</th>\n",
              "      <th>tBodyAcc-max()-Y</th>\n",
              "      <th>tBodyAcc-max()-Z</th>\n",
              "      <th>tBodyAcc-min()-X</th>\n",
              "      <th>tBodyAcc-min()-Y</th>\n",
              "      <th>tBodyAcc-min()-Z</th>\n",
              "      <th>tBodyAcc-sma()</th>\n",
              "      <th>tBodyAcc-energy()-X</th>\n",
              "      <th>tBodyAcc-energy()-Y</th>\n",
              "      <th>tBodyAcc-energy()-Z</th>\n",
              "      <th>tBodyAcc-iqr()-X</th>\n",
              "      <th>tBodyAcc-iqr()-Y</th>\n",
              "      <th>tBodyAcc-iqr()-Z</th>\n",
              "      <th>tBodyAcc-entropy()-X</th>\n",
              "      <th>tBodyAcc-entropy()-Y</th>\n",
              "      <th>tBodyAcc-entropy()-Z</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,4</th>\n",
              "      <th>tBodyAcc-correlation()-X,Y</th>\n",
              "      <th>tBodyAcc-correlation()-X,Z</th>\n",
              "      <th>tBodyAcc-correlation()-Y,Z</th>\n",
              "      <th>...</th>\n",
              "      <th>fBodyBodyAccJerkMag-iqr()</th>\n",
              "      <th>fBodyBodyAccJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyAccJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyAccJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyAccJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyAccJerkMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroMag-mean()</th>\n",
              "      <th>fBodyBodyGyroMag-std()</th>\n",
              "      <th>fBodyBodyGyroMag-mad()</th>\n",
              "      <th>fBodyBodyGyroMag-max()</th>\n",
              "      <th>fBodyBodyGyroMag-min()</th>\n",
              "      <th>fBodyBodyGyroMag-sma()</th>\n",
              "      <th>fBodyBodyGyroMag-energy()</th>\n",
              "      <th>fBodyBodyGyroMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mean()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-std()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mad()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-max()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-min()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-sma()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-energy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
              "      <th>angle(tBodyAccMean,gravity)</th>\n",
              "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
              "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
              "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
              "      <th>angle(X,gravityMean)</th>\n",
              "      <th>angle(Y,gravityMean)</th>\n",
              "      <th>angle(Z,gravityMean)</th>\n",
              "      <th>subject</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>WALKING</th>\n",
              "      <td>0.393036</td>\n",
              "      <td>-0.035508</td>\n",
              "      <td>-0.096930</td>\n",
              "      <td>-0.215820</td>\n",
              "      <td>0.023866</td>\n",
              "      <td>-0.251494</td>\n",
              "      <td>-0.249454</td>\n",
              "      <td>0.023258</td>\n",
              "      <td>-0.278413</td>\n",
              "      <td>-0.007768</td>\n",
              "      <td>-0.136535</td>\n",
              "      <td>-0.194124</td>\n",
              "      <td>0.210761</td>\n",
              "      <td>0.067789</td>\n",
              "      <td>0.345664</td>\n",
              "      <td>-0.098911</td>\n",
              "      <td>-0.688607</td>\n",
              "      <td>-0.796697</td>\n",
              "      <td>-0.745981</td>\n",
              "      <td>-0.319481</td>\n",
              "      <td>-0.160565</td>\n",
              "      <td>-0.357230</td>\n",
              "      <td>0.550041</td>\n",
              "      <td>0.338175</td>\n",
              "      <td>0.121285</td>\n",
              "      <td>-0.353071</td>\n",
              "      <td>0.212718</td>\n",
              "      <td>0.031531</td>\n",
              "      <td>0.050186</td>\n",
              "      <td>-0.431854</td>\n",
              "      <td>0.520354</td>\n",
              "      <td>-0.294795</td>\n",
              "      <td>0.090070</td>\n",
              "      <td>-0.408343</td>\n",
              "      <td>0.417422</td>\n",
              "      <td>-0.158423</td>\n",
              "      <td>-0.189919</td>\n",
              "      <td>0.030999</td>\n",
              "      <td>-0.016523</td>\n",
              "      <td>0.111382</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.454387</td>\n",
              "      <td>0.326371</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.065498</td>\n",
              "      <td>0.147117</td>\n",
              "      <td>-0.220220</td>\n",
              "      <td>-0.464997</td>\n",
              "      <td>-0.511719</td>\n",
              "      <td>-0.474567</td>\n",
              "      <td>-0.626406</td>\n",
              "      <td>-0.967318</td>\n",
              "      <td>-0.464997</td>\n",
              "      <td>-0.839093</td>\n",
              "      <td>-0.509740</td>\n",
              "      <td>0.542478</td>\n",
              "      <td>-0.589744</td>\n",
              "      <td>0.212420</td>\n",
              "      <td>-0.404980</td>\n",
              "      <td>-0.751005</td>\n",
              "      <td>-0.550479</td>\n",
              "      <td>-0.541014</td>\n",
              "      <td>-0.496765</td>\n",
              "      <td>-0.564387</td>\n",
              "      <td>-0.713698</td>\n",
              "      <td>-0.550479</td>\n",
              "      <td>-0.889402</td>\n",
              "      <td>-0.493091</td>\n",
              "      <td>0.384439</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.004302</td>\n",
              "      <td>-0.143888</td>\n",
              "      <td>-0.515889</td>\n",
              "      <td>-0.811886</td>\n",
              "      <td>0.419394</td>\n",
              "      <td>-0.418898</td>\n",
              "      <td>-0.313944</td>\n",
              "      <td>-0.696604</td>\n",
              "      <td>0.286523</td>\n",
              "      <td>0.111463</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STANDING</th>\n",
              "      <td>0.279812</td>\n",
              "      <td>-0.009229</td>\n",
              "      <td>-0.108859</td>\n",
              "      <td>-0.997079</td>\n",
              "      <td>-0.965516</td>\n",
              "      <td>-0.986990</td>\n",
              "      <td>-0.997420</td>\n",
              "      <td>-0.965268</td>\n",
              "      <td>-0.987193</td>\n",
              "      <td>-0.941530</td>\n",
              "      <td>-0.539611</td>\n",
              "      <td>-0.817126</td>\n",
              "      <td>0.850073</td>\n",
              "      <td>0.692724</td>\n",
              "      <td>0.838841</td>\n",
              "      <td>-0.987648</td>\n",
              "      <td>-0.999983</td>\n",
              "      <td>-0.999529</td>\n",
              "      <td>-0.999744</td>\n",
              "      <td>-0.997615</td>\n",
              "      <td>-0.970612</td>\n",
              "      <td>-0.987642</td>\n",
              "      <td>-0.633239</td>\n",
              "      <td>-0.264292</td>\n",
              "      <td>-0.566508</td>\n",
              "      <td>0.207631</td>\n",
              "      <td>-0.031244</td>\n",
              "      <td>0.100655</td>\n",
              "      <td>0.070045</td>\n",
              "      <td>0.251341</td>\n",
              "      <td>-0.228236</td>\n",
              "      <td>0.336316</td>\n",
              "      <td>-0.301663</td>\n",
              "      <td>0.343729</td>\n",
              "      <td>-0.049137</td>\n",
              "      <td>0.033284</td>\n",
              "      <td>0.046999</td>\n",
              "      <td>0.169059</td>\n",
              "      <td>-0.176466</td>\n",
              "      <td>0.052964</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.988779</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.746032</td>\n",
              "      <td>0.131102</td>\n",
              "      <td>-0.542409</td>\n",
              "      <td>-0.859902</td>\n",
              "      <td>-0.990110</td>\n",
              "      <td>-0.986167</td>\n",
              "      <td>-0.986907</td>\n",
              "      <td>-0.984611</td>\n",
              "      <td>-0.997127</td>\n",
              "      <td>-0.990110</td>\n",
              "      <td>-0.999862</td>\n",
              "      <td>-0.989437</td>\n",
              "      <td>-0.787033</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.183476</td>\n",
              "      <td>-0.043566</td>\n",
              "      <td>-0.356218</td>\n",
              "      <td>-0.995061</td>\n",
              "      <td>-0.995303</td>\n",
              "      <td>-0.994247</td>\n",
              "      <td>-0.996168</td>\n",
              "      <td>-0.994639</td>\n",
              "      <td>-0.995061</td>\n",
              "      <td>-0.999974</td>\n",
              "      <td>-0.992389</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.126509</td>\n",
              "      <td>-0.586242</td>\n",
              "      <td>-0.856196</td>\n",
              "      <td>0.002088</td>\n",
              "      <td>0.064013</td>\n",
              "      <td>-0.132991</td>\n",
              "      <td>0.619262</td>\n",
              "      <td>-0.897183</td>\n",
              "      <td>0.168929</td>\n",
              "      <td>0.010264</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WALKING_UPSTAIRS</th>\n",
              "      <td>0.181504</td>\n",
              "      <td>-0.094074</td>\n",
              "      <td>-0.178262</td>\n",
              "      <td>-0.064572</td>\n",
              "      <td>-0.109424</td>\n",
              "      <td>-0.334114</td>\n",
              "      <td>-0.192659</td>\n",
              "      <td>-0.161285</td>\n",
              "      <td>-0.324384</td>\n",
              "      <td>0.171278</td>\n",
              "      <td>-0.080983</td>\n",
              "      <td>-0.464330</td>\n",
              "      <td>-0.027124</td>\n",
              "      <td>0.192982</td>\n",
              "      <td>0.445468</td>\n",
              "      <td>-0.120994</td>\n",
              "      <td>-0.559647</td>\n",
              "      <td>-0.835535</td>\n",
              "      <td>-0.790828</td>\n",
              "      <td>-0.408826</td>\n",
              "      <td>-0.450907</td>\n",
              "      <td>-0.283662</td>\n",
              "      <td>0.555870</td>\n",
              "      <td>0.004598</td>\n",
              "      <td>-0.126710</td>\n",
              "      <td>-0.258173</td>\n",
              "      <td>0.128774</td>\n",
              "      <td>-0.100619</td>\n",
              "      <td>0.293648</td>\n",
              "      <td>-0.231463</td>\n",
              "      <td>0.152564</td>\n",
              "      <td>-0.080707</td>\n",
              "      <td>0.368134</td>\n",
              "      <td>-0.178401</td>\n",
              "      <td>0.128177</td>\n",
              "      <td>-0.152636</td>\n",
              "      <td>0.146911</td>\n",
              "      <td>-0.530165</td>\n",
              "      <td>-0.139394</td>\n",
              "      <td>0.079164</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.366518</td>\n",
              "      <td>0.391105</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.025713</td>\n",
              "      <td>-0.545957</td>\n",
              "      <td>-0.887389</td>\n",
              "      <td>-0.594526</td>\n",
              "      <td>-0.593518</td>\n",
              "      <td>-0.520026</td>\n",
              "      <td>-0.703995</td>\n",
              "      <td>-0.874617</td>\n",
              "      <td>-0.594526</td>\n",
              "      <td>-0.896619</td>\n",
              "      <td>-0.524962</td>\n",
              "      <td>0.453639</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.177945</td>\n",
              "      <td>-0.533271</td>\n",
              "      <td>-0.838579</td>\n",
              "      <td>-0.712239</td>\n",
              "      <td>-0.723833</td>\n",
              "      <td>-0.665446</td>\n",
              "      <td>-0.808143</td>\n",
              "      <td>-0.863407</td>\n",
              "      <td>-0.712239</td>\n",
              "      <td>-0.956748</td>\n",
              "      <td>-0.714184</td>\n",
              "      <td>0.237073</td>\n",
              "      <td>-0.746032</td>\n",
              "      <td>-0.108181</td>\n",
              "      <td>-0.493719</td>\n",
              "      <td>-0.864203</td>\n",
              "      <td>0.165913</td>\n",
              "      <td>-0.833641</td>\n",
              "      <td>-0.965221</td>\n",
              "      <td>0.570291</td>\n",
              "      <td>-0.811279</td>\n",
              "      <td>0.227645</td>\n",
              "      <td>0.001561</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STANDING</th>\n",
              "      <td>0.274355</td>\n",
              "      <td>-0.007671</td>\n",
              "      <td>-0.091210</td>\n",
              "      <td>-0.997025</td>\n",
              "      <td>-0.959407</td>\n",
              "      <td>-0.980479</td>\n",
              "      <td>-0.997336</td>\n",
              "      <td>-0.958406</td>\n",
              "      <td>-0.979852</td>\n",
              "      <td>-0.942288</td>\n",
              "      <td>-0.550698</td>\n",
              "      <td>-0.794378</td>\n",
              "      <td>0.846971</td>\n",
              "      <td>0.680981</td>\n",
              "      <td>0.847907</td>\n",
              "      <td>-0.978340</td>\n",
              "      <td>-0.999981</td>\n",
              "      <td>-0.999370</td>\n",
              "      <td>-0.999127</td>\n",
              "      <td>-0.996922</td>\n",
              "      <td>-0.965393</td>\n",
              "      <td>-0.978856</td>\n",
              "      <td>-0.777403</td>\n",
              "      <td>-0.202338</td>\n",
              "      <td>-0.203109</td>\n",
              "      <td>0.317901</td>\n",
              "      <td>-0.197911</td>\n",
              "      <td>0.144051</td>\n",
              "      <td>0.147647</td>\n",
              "      <td>0.119012</td>\n",
              "      <td>-0.181318</td>\n",
              "      <td>0.326227</td>\n",
              "      <td>-0.274933</td>\n",
              "      <td>0.323862</td>\n",
              "      <td>-0.195119</td>\n",
              "      <td>0.042358</td>\n",
              "      <td>-0.118700</td>\n",
              "      <td>-0.306203</td>\n",
              "      <td>-0.415106</td>\n",
              "      <td>0.420246</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.988727</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.968254</td>\n",
              "      <td>0.213542</td>\n",
              "      <td>-0.487898</td>\n",
              "      <td>-0.812442</td>\n",
              "      <td>-0.988428</td>\n",
              "      <td>-0.979051</td>\n",
              "      <td>-0.982773</td>\n",
              "      <td>-0.973671</td>\n",
              "      <td>-0.996712</td>\n",
              "      <td>-0.988428</td>\n",
              "      <td>-0.999745</td>\n",
              "      <td>-0.989797</td>\n",
              "      <td>-0.707158</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.385725</td>\n",
              "      <td>0.438079</td>\n",
              "      <td>0.262306</td>\n",
              "      <td>-0.995866</td>\n",
              "      <td>-0.995003</td>\n",
              "      <td>-0.994314</td>\n",
              "      <td>-0.995021</td>\n",
              "      <td>-0.993850</td>\n",
              "      <td>-0.995866</td>\n",
              "      <td>-0.999977</td>\n",
              "      <td>-0.993857</td>\n",
              "      <td>-0.955696</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.209376</td>\n",
              "      <td>-0.326697</td>\n",
              "      <td>-0.647329</td>\n",
              "      <td>0.015935</td>\n",
              "      <td>0.852904</td>\n",
              "      <td>-0.162749</td>\n",
              "      <td>0.613947</td>\n",
              "      <td>-0.927014</td>\n",
              "      <td>0.071032</td>\n",
              "      <td>-0.029895</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WALKING_UPSTAIRS</th>\n",
              "      <td>0.264330</td>\n",
              "      <td>-0.022072</td>\n",
              "      <td>-0.133379</td>\n",
              "      <td>-0.214011</td>\n",
              "      <td>-0.162882</td>\n",
              "      <td>-0.178638</td>\n",
              "      <td>-0.250467</td>\n",
              "      <td>-0.164771</td>\n",
              "      <td>-0.130833</td>\n",
              "      <td>-0.111599</td>\n",
              "      <td>-0.165973</td>\n",
              "      <td>-0.233832</td>\n",
              "      <td>0.194350</td>\n",
              "      <td>0.160491</td>\n",
              "      <td>0.609134</td>\n",
              "      <td>-0.101119</td>\n",
              "      <td>-0.689837</td>\n",
              "      <td>-0.863871</td>\n",
              "      <td>-0.694592</td>\n",
              "      <td>-0.352650</td>\n",
              "      <td>-0.352433</td>\n",
              "      <td>0.069769</td>\n",
              "      <td>0.369768</td>\n",
              "      <td>0.355094</td>\n",
              "      <td>-0.099550</td>\n",
              "      <td>-0.410768</td>\n",
              "      <td>0.127222</td>\n",
              "      <td>0.217652</td>\n",
              "      <td>-0.063501</td>\n",
              "      <td>-0.338611</td>\n",
              "      <td>0.173621</td>\n",
              "      <td>0.283435</td>\n",
              "      <td>-0.246335</td>\n",
              "      <td>-0.189470</td>\n",
              "      <td>-0.046043</td>\n",
              "      <td>0.103780</td>\n",
              "      <td>0.078292</td>\n",
              "      <td>-0.611718</td>\n",
              "      <td>-0.009630</td>\n",
              "      <td>-0.054256</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.521296</td>\n",
              "      <td>0.193176</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.073267</td>\n",
              "      <td>-0.313994</td>\n",
              "      <td>-0.607739</td>\n",
              "      <td>-0.609436</td>\n",
              "      <td>-0.514242</td>\n",
              "      <td>-0.523293</td>\n",
              "      <td>-0.510078</td>\n",
              "      <td>-0.961622</td>\n",
              "      <td>-0.609436</td>\n",
              "      <td>-0.873047</td>\n",
              "      <td>-0.645964</td>\n",
              "      <td>0.309884</td>\n",
              "      <td>-0.846154</td>\n",
              "      <td>-0.250707</td>\n",
              "      <td>-0.081151</td>\n",
              "      <td>-0.424309</td>\n",
              "      <td>-0.785736</td>\n",
              "      <td>-0.785760</td>\n",
              "      <td>-0.779711</td>\n",
              "      <td>-0.812551</td>\n",
              "      <td>-0.845610</td>\n",
              "      <td>-0.785736</td>\n",
              "      <td>-0.975010</td>\n",
              "      <td>-0.803764</td>\n",
              "      <td>0.070988</td>\n",
              "      <td>-0.777778</td>\n",
              "      <td>-0.011800</td>\n",
              "      <td>-0.130592</td>\n",
              "      <td>-0.559576</td>\n",
              "      <td>0.231335</td>\n",
              "      <td>-0.100702</td>\n",
              "      <td>0.944175</td>\n",
              "      <td>-0.938698</td>\n",
              "      <td>-0.613441</td>\n",
              "      <td>0.332565</td>\n",
              "      <td>-0.110461</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 562 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  tBodyAcc-mean()-X  ...  subject\n",
              "Activity                             ...         \n",
              "WALKING                    0.393036  ...       17\n",
              "STANDING                   0.279812  ...       15\n",
              "WALKING_UPSTAIRS           0.181504  ...       26\n",
              "STANDING                   0.274355  ...       29\n",
              "WALKING_UPSTAIRS           0.264330  ...       11\n",
              "\n",
              "[5 rows x 562 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhlcKo1OYl6d",
        "outputId": "3f239a12-8725-49c5-ba74-55ff23b30412"
      },
      "source": [
        "print('size of data train',df_train.shape)\r\n",
        "print('size of data test',df_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of data train (7352, 562)\n",
            "size of data test (2947, 562)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "1AR8n98hYl-6",
        "outputId": "111e336a-4266-402c-aca6-40ae40fbaf93"
      },
      "source": [
        "pd.crosstab(index = df_train.index, columns=\"count\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LAYING</th>\n",
              "      <td>1407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SITTING</th>\n",
              "      <td>1286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STANDING</th>\n",
              "      <td>1374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WALKING</th>\n",
              "      <td>1226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WALKING_DOWNSTAIRS</th>\n",
              "      <td>986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WALKING_UPSTAIRS</th>\n",
              "      <td>1073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0               count\n",
              "row_0                    \n",
              "LAYING               1407\n",
              "SITTING              1286\n",
              "STANDING             1374\n",
              "WALKING              1226\n",
              "WALKING_DOWNSTAIRS    986\n",
              "WALKING_UPSTAIRS     1073"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "sZ976qW3YmDw",
        "outputId": "c77e67a9-5c42-4a32-bcd0-9c8cf980f056"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "ax = sns.countplot(x=df_train.index, data=df_train)\r\n",
        "plt.xticks(x = df_train.index,  rotation='vertical')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfJhkL8tZydF",
        "outputId": "554e6296-71df-4506-d492-4be9d84b99c8"
      },
      "source": [
        "df_train.index.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['WALKING', 'STANDING', 'WALKING_UPSTAIRS', 'LAYING', 'SITTING',\n",
              "       'WALKING_DOWNSTAIRS'],\n",
              "      dtype='object', name='Activity')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgUSRWMiZyqA"
      },
      "source": [
        "StaticTrain = df_train.loc[['STANDING','SITTING','LAYING']]\r\n",
        "StaticTest = df_test.loc[['STANDING','SITTING','LAYING']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTP3nDvdZyxh",
        "outputId": "851ba3a8-9829-4350-ca58-bab0510838ba"
      },
      "source": [
        "StaticTrain.index.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['STANDING', 'SITTING', 'LAYING'], dtype='object', name='Activity')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgKUqLGxZy2Z",
        "outputId": "3334c5d3-efe6-41da-a29b-e7d0d250dbf2"
      },
      "source": [
        "StaticTest.index.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['STANDING', 'SITTING', 'LAYING'], dtype='object', name='Activity')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwMxb1ILZy6e"
      },
      "source": [
        "subject_training_data = StaticTrain['subject']\r\n",
        "subject_testing_data = StaticTest['subject']\r\n",
        "StaticTrain = StaticTrain.drop(['subject'], axis=1)\r\n",
        "StaticTest = StaticTest.drop(['subject'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "bLocjhYoZzAE",
        "outputId": "2d832afd-0d2a-45f4-9223-4215a43ed622"
      },
      "source": [
        "StaticTrain.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tBodyAcc-mean()-X</th>\n",
              "      <th>tBodyAcc-mean()-Y</th>\n",
              "      <th>tBodyAcc-mean()-Z</th>\n",
              "      <th>tBodyAcc-std()-X</th>\n",
              "      <th>tBodyAcc-std()-Y</th>\n",
              "      <th>tBodyAcc-std()-Z</th>\n",
              "      <th>tBodyAcc-mad()-X</th>\n",
              "      <th>tBodyAcc-mad()-Y</th>\n",
              "      <th>tBodyAcc-mad()-Z</th>\n",
              "      <th>tBodyAcc-max()-X</th>\n",
              "      <th>tBodyAcc-max()-Y</th>\n",
              "      <th>tBodyAcc-max()-Z</th>\n",
              "      <th>tBodyAcc-min()-X</th>\n",
              "      <th>tBodyAcc-min()-Y</th>\n",
              "      <th>tBodyAcc-min()-Z</th>\n",
              "      <th>tBodyAcc-sma()</th>\n",
              "      <th>tBodyAcc-energy()-X</th>\n",
              "      <th>tBodyAcc-energy()-Y</th>\n",
              "      <th>tBodyAcc-energy()-Z</th>\n",
              "      <th>tBodyAcc-iqr()-X</th>\n",
              "      <th>tBodyAcc-iqr()-Y</th>\n",
              "      <th>tBodyAcc-iqr()-Z</th>\n",
              "      <th>tBodyAcc-entropy()-X</th>\n",
              "      <th>tBodyAcc-entropy()-Y</th>\n",
              "      <th>tBodyAcc-entropy()-Z</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,4</th>\n",
              "      <th>tBodyAcc-correlation()-X,Y</th>\n",
              "      <th>tBodyAcc-correlation()-X,Z</th>\n",
              "      <th>tBodyAcc-correlation()-Y,Z</th>\n",
              "      <th>...</th>\n",
              "      <th>fBodyBodyAccJerkMag-energy()</th>\n",
              "      <th>fBodyBodyAccJerkMag-iqr()</th>\n",
              "      <th>fBodyBodyAccJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyAccJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyAccJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyAccJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyAccJerkMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroMag-mean()</th>\n",
              "      <th>fBodyBodyGyroMag-std()</th>\n",
              "      <th>fBodyBodyGyroMag-mad()</th>\n",
              "      <th>fBodyBodyGyroMag-max()</th>\n",
              "      <th>fBodyBodyGyroMag-min()</th>\n",
              "      <th>fBodyBodyGyroMag-sma()</th>\n",
              "      <th>fBodyBodyGyroMag-energy()</th>\n",
              "      <th>fBodyBodyGyroMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mean()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-std()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mad()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-max()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-min()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-sma()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-energy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
              "      <th>angle(tBodyAccMean,gravity)</th>\n",
              "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
              "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
              "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
              "      <th>angle(X,gravityMean)</th>\n",
              "      <th>angle(Y,gravityMean)</th>\n",
              "      <th>angle(Z,gravityMean)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>STANDING</th>\n",
              "      <td>0.279812</td>\n",
              "      <td>-0.009229</td>\n",
              "      <td>-0.108859</td>\n",
              "      <td>-0.997079</td>\n",
              "      <td>-0.965516</td>\n",
              "      <td>-0.986990</td>\n",
              "      <td>-0.997420</td>\n",
              "      <td>-0.965268</td>\n",
              "      <td>-0.987193</td>\n",
              "      <td>-0.941530</td>\n",
              "      <td>-0.539611</td>\n",
              "      <td>-0.817126</td>\n",
              "      <td>0.850073</td>\n",
              "      <td>0.692724</td>\n",
              "      <td>0.838841</td>\n",
              "      <td>-0.987648</td>\n",
              "      <td>-0.999983</td>\n",
              "      <td>-0.999529</td>\n",
              "      <td>-0.999744</td>\n",
              "      <td>-0.997615</td>\n",
              "      <td>-0.970612</td>\n",
              "      <td>-0.987642</td>\n",
              "      <td>-0.633239</td>\n",
              "      <td>-0.264292</td>\n",
              "      <td>-0.566508</td>\n",
              "      <td>0.207631</td>\n",
              "      <td>-0.031244</td>\n",
              "      <td>0.100655</td>\n",
              "      <td>0.070045</td>\n",
              "      <td>0.251341</td>\n",
              "      <td>-0.228236</td>\n",
              "      <td>0.336316</td>\n",
              "      <td>-0.301663</td>\n",
              "      <td>0.343729</td>\n",
              "      <td>-0.049137</td>\n",
              "      <td>0.033284</td>\n",
              "      <td>0.046999</td>\n",
              "      <td>0.169059</td>\n",
              "      <td>-0.176466</td>\n",
              "      <td>0.052964</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999756</td>\n",
              "      <td>-0.988779</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.746032</td>\n",
              "      <td>0.131102</td>\n",
              "      <td>-0.542409</td>\n",
              "      <td>-0.859902</td>\n",
              "      <td>-0.990110</td>\n",
              "      <td>-0.986167</td>\n",
              "      <td>-0.986907</td>\n",
              "      <td>-0.984611</td>\n",
              "      <td>-0.997127</td>\n",
              "      <td>-0.990110</td>\n",
              "      <td>-0.999862</td>\n",
              "      <td>-0.989437</td>\n",
              "      <td>-0.787033</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.183476</td>\n",
              "      <td>-0.043566</td>\n",
              "      <td>-0.356218</td>\n",
              "      <td>-0.995061</td>\n",
              "      <td>-0.995303</td>\n",
              "      <td>-0.994247</td>\n",
              "      <td>-0.996168</td>\n",
              "      <td>-0.994639</td>\n",
              "      <td>-0.995061</td>\n",
              "      <td>-0.999974</td>\n",
              "      <td>-0.992389</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.126509</td>\n",
              "      <td>-0.586242</td>\n",
              "      <td>-0.856196</td>\n",
              "      <td>0.002088</td>\n",
              "      <td>0.064013</td>\n",
              "      <td>-0.132991</td>\n",
              "      <td>0.619262</td>\n",
              "      <td>-0.897183</td>\n",
              "      <td>0.168929</td>\n",
              "      <td>0.010264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STANDING</th>\n",
              "      <td>0.274355</td>\n",
              "      <td>-0.007671</td>\n",
              "      <td>-0.091210</td>\n",
              "      <td>-0.997025</td>\n",
              "      <td>-0.959407</td>\n",
              "      <td>-0.980479</td>\n",
              "      <td>-0.997336</td>\n",
              "      <td>-0.958406</td>\n",
              "      <td>-0.979852</td>\n",
              "      <td>-0.942288</td>\n",
              "      <td>-0.550698</td>\n",
              "      <td>-0.794378</td>\n",
              "      <td>0.846971</td>\n",
              "      <td>0.680981</td>\n",
              "      <td>0.847907</td>\n",
              "      <td>-0.978340</td>\n",
              "      <td>-0.999981</td>\n",
              "      <td>-0.999370</td>\n",
              "      <td>-0.999127</td>\n",
              "      <td>-0.996922</td>\n",
              "      <td>-0.965393</td>\n",
              "      <td>-0.978856</td>\n",
              "      <td>-0.777403</td>\n",
              "      <td>-0.202338</td>\n",
              "      <td>-0.203109</td>\n",
              "      <td>0.317901</td>\n",
              "      <td>-0.197911</td>\n",
              "      <td>0.144051</td>\n",
              "      <td>0.147647</td>\n",
              "      <td>0.119012</td>\n",
              "      <td>-0.181318</td>\n",
              "      <td>0.326227</td>\n",
              "      <td>-0.274933</td>\n",
              "      <td>0.323862</td>\n",
              "      <td>-0.195119</td>\n",
              "      <td>0.042358</td>\n",
              "      <td>-0.118700</td>\n",
              "      <td>-0.306203</td>\n",
              "      <td>-0.415106</td>\n",
              "      <td>0.420246</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999852</td>\n",
              "      <td>-0.988727</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.968254</td>\n",
              "      <td>0.213542</td>\n",
              "      <td>-0.487898</td>\n",
              "      <td>-0.812442</td>\n",
              "      <td>-0.988428</td>\n",
              "      <td>-0.979051</td>\n",
              "      <td>-0.982773</td>\n",
              "      <td>-0.973671</td>\n",
              "      <td>-0.996712</td>\n",
              "      <td>-0.988428</td>\n",
              "      <td>-0.999745</td>\n",
              "      <td>-0.989797</td>\n",
              "      <td>-0.707158</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.385725</td>\n",
              "      <td>0.438079</td>\n",
              "      <td>0.262306</td>\n",
              "      <td>-0.995866</td>\n",
              "      <td>-0.995003</td>\n",
              "      <td>-0.994314</td>\n",
              "      <td>-0.995021</td>\n",
              "      <td>-0.993850</td>\n",
              "      <td>-0.995866</td>\n",
              "      <td>-0.999977</td>\n",
              "      <td>-0.993857</td>\n",
              "      <td>-0.955696</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.209376</td>\n",
              "      <td>-0.326697</td>\n",
              "      <td>-0.647329</td>\n",
              "      <td>0.015935</td>\n",
              "      <td>0.852904</td>\n",
              "      <td>-0.162749</td>\n",
              "      <td>0.613947</td>\n",
              "      <td>-0.927014</td>\n",
              "      <td>0.071032</td>\n",
              "      <td>-0.029895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STANDING</th>\n",
              "      <td>0.282672</td>\n",
              "      <td>-0.058369</td>\n",
              "      <td>-0.166825</td>\n",
              "      <td>-0.980440</td>\n",
              "      <td>-0.848483</td>\n",
              "      <td>-0.898052</td>\n",
              "      <td>-0.986289</td>\n",
              "      <td>-0.829429</td>\n",
              "      <td>-0.882769</td>\n",
              "      <td>-0.900349</td>\n",
              "      <td>-0.556719</td>\n",
              "      <td>-0.816139</td>\n",
              "      <td>0.837684</td>\n",
              "      <td>0.612476</td>\n",
              "      <td>0.776590</td>\n",
              "      <td>-0.899688</td>\n",
              "      <td>-0.999721</td>\n",
              "      <td>-0.992002</td>\n",
              "      <td>-0.988965</td>\n",
              "      <td>-0.993175</td>\n",
              "      <td>-0.831883</td>\n",
              "      <td>-0.853685</td>\n",
              "      <td>-0.383307</td>\n",
              "      <td>-0.494256</td>\n",
              "      <td>-0.559039</td>\n",
              "      <td>0.304026</td>\n",
              "      <td>-0.177280</td>\n",
              "      <td>0.260106</td>\n",
              "      <td>-0.093155</td>\n",
              "      <td>-0.106270</td>\n",
              "      <td>-0.021687</td>\n",
              "      <td>0.035313</td>\n",
              "      <td>0.181930</td>\n",
              "      <td>0.478265</td>\n",
              "      <td>-0.329913</td>\n",
              "      <td>0.300349</td>\n",
              "      <td>-0.571331</td>\n",
              "      <td>-0.437396</td>\n",
              "      <td>-0.475934</td>\n",
              "      <td>0.948190</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999133</td>\n",
              "      <td>-0.972112</td>\n",
              "      <td>-0.940965</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.018322</td>\n",
              "      <td>0.098497</td>\n",
              "      <td>-0.231433</td>\n",
              "      <td>-0.968030</td>\n",
              "      <td>-0.956244</td>\n",
              "      <td>-0.956340</td>\n",
              "      <td>-0.967464</td>\n",
              "      <td>-0.998075</td>\n",
              "      <td>-0.968030</td>\n",
              "      <td>-0.998898</td>\n",
              "      <td>-0.977152</td>\n",
              "      <td>-0.508568</td>\n",
              "      <td>-0.743590</td>\n",
              "      <td>-0.319764</td>\n",
              "      <td>-0.315080</td>\n",
              "      <td>-0.724009</td>\n",
              "      <td>-0.983214</td>\n",
              "      <td>-0.977860</td>\n",
              "      <td>-0.981099</td>\n",
              "      <td>-0.973913</td>\n",
              "      <td>-0.998757</td>\n",
              "      <td>-0.983214</td>\n",
              "      <td>-0.999749</td>\n",
              "      <td>-0.984820</td>\n",
              "      <td>-0.766676</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.001551</td>\n",
              "      <td>0.459117</td>\n",
              "      <td>0.237683</td>\n",
              "      <td>0.014769</td>\n",
              "      <td>0.129238</td>\n",
              "      <td>-0.352420</td>\n",
              "      <td>-0.022525</td>\n",
              "      <td>-0.943854</td>\n",
              "      <td>0.084822</td>\n",
              "      <td>-0.022861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STANDING</th>\n",
              "      <td>0.277530</td>\n",
              "      <td>-0.020664</td>\n",
              "      <td>-0.106117</td>\n",
              "      <td>-0.996955</td>\n",
              "      <td>-0.969600</td>\n",
              "      <td>-0.966983</td>\n",
              "      <td>-0.997395</td>\n",
              "      <td>-0.972061</td>\n",
              "      <td>-0.963284</td>\n",
              "      <td>-0.937662</td>\n",
              "      <td>-0.557504</td>\n",
              "      <td>-0.805561</td>\n",
              "      <td>0.850252</td>\n",
              "      <td>0.677608</td>\n",
              "      <td>0.835303</td>\n",
              "      <td>-0.982411</td>\n",
              "      <td>-0.999983</td>\n",
              "      <td>-0.999685</td>\n",
              "      <td>-0.999047</td>\n",
              "      <td>-0.997540</td>\n",
              "      <td>-0.985163</td>\n",
              "      <td>-0.959806</td>\n",
              "      <td>-0.695705</td>\n",
              "      <td>-0.612814</td>\n",
              "      <td>-0.357634</td>\n",
              "      <td>0.389421</td>\n",
              "      <td>-0.148238</td>\n",
              "      <td>0.102929</td>\n",
              "      <td>0.251706</td>\n",
              "      <td>0.161991</td>\n",
              "      <td>-0.197619</td>\n",
              "      <td>0.325335</td>\n",
              "      <td>-0.268765</td>\n",
              "      <td>0.189387</td>\n",
              "      <td>-0.090653</td>\n",
              "      <td>0.019887</td>\n",
              "      <td>-0.219230</td>\n",
              "      <td>0.341079</td>\n",
              "      <td>-0.136935</td>\n",
              "      <td>-0.114809</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999941</td>\n",
              "      <td>-0.994258</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.488931</td>\n",
              "      <td>-0.457608</td>\n",
              "      <td>-0.748063</td>\n",
              "      <td>-0.990475</td>\n",
              "      <td>-0.986181</td>\n",
              "      <td>-0.985975</td>\n",
              "      <td>-0.988344</td>\n",
              "      <td>-0.996153</td>\n",
              "      <td>-0.990475</td>\n",
              "      <td>-0.999864</td>\n",
              "      <td>-0.990235</td>\n",
              "      <td>-0.751496</td>\n",
              "      <td>-0.948718</td>\n",
              "      <td>-0.289097</td>\n",
              "      <td>-0.322002</td>\n",
              "      <td>-0.699302</td>\n",
              "      <td>-0.996976</td>\n",
              "      <td>-0.997218</td>\n",
              "      <td>-0.996511</td>\n",
              "      <td>-0.997360</td>\n",
              "      <td>-0.996302</td>\n",
              "      <td>-0.996976</td>\n",
              "      <td>-0.999987</td>\n",
              "      <td>-0.995006</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.513089</td>\n",
              "      <td>-0.592963</td>\n",
              "      <td>-0.822086</td>\n",
              "      <td>-0.093482</td>\n",
              "      <td>0.031847</td>\n",
              "      <td>0.744458</td>\n",
              "      <td>0.811900</td>\n",
              "      <td>-0.814470</td>\n",
              "      <td>0.224863</td>\n",
              "      <td>0.038279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STANDING</th>\n",
              "      <td>0.282168</td>\n",
              "      <td>-0.012056</td>\n",
              "      <td>-0.118639</td>\n",
              "      <td>-0.993666</td>\n",
              "      <td>-0.971853</td>\n",
              "      <td>-0.974106</td>\n",
              "      <td>-0.994363</td>\n",
              "      <td>-0.973372</td>\n",
              "      <td>-0.976120</td>\n",
              "      <td>-0.934424</td>\n",
              "      <td>-0.560671</td>\n",
              "      <td>-0.804711</td>\n",
              "      <td>0.843627</td>\n",
              "      <td>0.677679</td>\n",
              "      <td>0.838073</td>\n",
              "      <td>-0.980346</td>\n",
              "      <td>-0.999949</td>\n",
              "      <td>-0.999695</td>\n",
              "      <td>-0.999182</td>\n",
              "      <td>-0.994240</td>\n",
              "      <td>-0.976319</td>\n",
              "      <td>-0.976761</td>\n",
              "      <td>-0.480765</td>\n",
              "      <td>-0.356918</td>\n",
              "      <td>-0.623109</td>\n",
              "      <td>0.098048</td>\n",
              "      <td>-0.014566</td>\n",
              "      <td>-0.108271</td>\n",
              "      <td>0.470203</td>\n",
              "      <td>0.037795</td>\n",
              "      <td>-0.144199</td>\n",
              "      <td>0.257446</td>\n",
              "      <td>0.043561</td>\n",
              "      <td>0.007187</td>\n",
              "      <td>-0.046156</td>\n",
              "      <td>-0.041423</td>\n",
              "      <td>0.182491</td>\n",
              "      <td>-0.045048</td>\n",
              "      <td>-0.207902</td>\n",
              "      <td>-0.154220</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999921</td>\n",
              "      <td>-0.992510</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.968254</td>\n",
              "      <td>0.378264</td>\n",
              "      <td>-0.671743</td>\n",
              "      <td>-0.912895</td>\n",
              "      <td>-0.985957</td>\n",
              "      <td>-0.982868</td>\n",
              "      <td>-0.982587</td>\n",
              "      <td>-0.982261</td>\n",
              "      <td>-0.995885</td>\n",
              "      <td>-0.985957</td>\n",
              "      <td>-0.999785</td>\n",
              "      <td>-0.983753</td>\n",
              "      <td>-0.676828</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.148030</td>\n",
              "      <td>-0.161161</td>\n",
              "      <td>-0.493722</td>\n",
              "      <td>-0.993300</td>\n",
              "      <td>-0.995507</td>\n",
              "      <td>-0.994498</td>\n",
              "      <td>-0.996591</td>\n",
              "      <td>-0.991096</td>\n",
              "      <td>-0.993300</td>\n",
              "      <td>-0.999965</td>\n",
              "      <td>-0.994651</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.492063</td>\n",
              "      <td>0.539241</td>\n",
              "      <td>-0.682694</td>\n",
              "      <td>-0.916376</td>\n",
              "      <td>-0.055711</td>\n",
              "      <td>0.150180</td>\n",
              "      <td>-0.270495</td>\n",
              "      <td>-0.663620</td>\n",
              "      <td>-0.830593</td>\n",
              "      <td>0.214673</td>\n",
              "      <td>0.005633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 561 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          tBodyAcc-mean()-X  ...  angle(Z,gravityMean)\n",
              "Activity                     ...                      \n",
              "STANDING           0.279812  ...              0.010264\n",
              "STANDING           0.274355  ...             -0.029895\n",
              "STANDING           0.282672  ...             -0.022861\n",
              "STANDING           0.277530  ...              0.038279\n",
              "STANDING           0.282168  ...              0.005633\n",
              "\n",
              "[5 rows x 561 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZEzeWUWZzIN"
      },
      "source": [
        "training_labels = StaticTrain.index\r\n",
        "testing_labels = StaticTest.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz9fEOHsZzNY"
      },
      "source": [
        "StaticTrain.reset_index(drop=True, inplace=True)\r\n",
        "StaticTest.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIG4YfQ7ZzS_",
        "outputId": "33e529d0-d7c5-4263-9395-f20fc9040353"
      },
      "source": [
        "StaticTrain.index.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
              "            ...\n",
              "            4057, 4058, 4059, 4060, 4061, 4062, 4063, 4064, 4065, 4066],\n",
              "           dtype='int64', length=4067)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L88Jf2qcsNi",
        "outputId": "7971af08-3920-476f-998a-41e1ad7321da"
      },
      "source": [
        "StaticTest.index.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
              "            ...\n",
              "            1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559],\n",
              "           dtype='int64', length=1560)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlYB0IKNZzYC",
        "outputId": "0913f0ac-a09d-4b04-d460-7f016179f268"
      },
      "source": [
        "print (\"Training data consists of {} instances of data with {} total features\".format(StaticTrain.shape[0], StaticTrain.shape[1]))\r\n",
        "print (\"Training data includes value counts of\\n\",training_labels.value_counts())\r\n",
        "print (\"\\n\")\r\n",
        "print (\"Testing data consists of {} instances of data\".format(df_test.shape[0]))\r\n",
        "print (\"Testing data includes value counts of\\n\",testing_labels.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data consists of 4067 instances of data with 561 total features\n",
            "Training data includes value counts of\n",
            " LAYING      1407\n",
            "STANDING    1374\n",
            "SITTING     1286\n",
            "Name: Activity, dtype: int64\n",
            "\n",
            "\n",
            "Testing data consists of 2947 instances of data\n",
            "Testing data includes value counts of\n",
            " LAYING      537\n",
            "STANDING    532\n",
            "SITTING     491\n",
            "Name: Activity, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3dM_GXGZzd0",
        "outputId": "53748cd2-e19a-481b-c685-5740021b56c6"
      },
      "source": [
        "numerics = ['int16','int32','int64','float16','float32','float64']\r\n",
        "numerical_vars = list(StaticTrain.select_dtypes(include=numerics).columns)\r\n",
        "X_train = StaticTrain#[numerical_vars]\r\n",
        "X_train.shape\r\n",
        "#X_train.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "561"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hkk4odKvbvkm",
        "outputId": "86d07298-0bd5-4d46-96a7-bd4c6de10375"
      },
      "source": [
        "numerical_vars = list(StaticTest.select_dtypes(include=numerics).columns)\r\n",
        "X_test = StaticTest#[numerical_vars]\r\n",
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1560, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W1mZEt4bvxZ"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "le = LabelEncoder()\r\n",
        "le = le.fit([\"SITTING\", \"STANDING\", \"LAYING\"])\r\n",
        "y_train = le.transform(training_labels)  \r\n",
        "y_test = le.transform(testing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4G1F0_zpbv4K",
        "outputId": "f876b6b6-3d58-4702-fe4b-4e25e6a1e75b"
      },
      "source": [
        "le.classes_[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'STANDING'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xYAcftd3M7w",
        "outputId": "779b6a28-ca19-482b-ad0f-5093e2056055"
      },
      "source": [
        "#normalize\r\n",
        "X_train = X_train / 255.0\r\n",
        "X_test = X_test / 255.0\r\n",
        "print (\"X_train shape: \",X_train.shape)\r\n",
        "print (\"X_test shape: \",X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (4067, 561)\n",
            "X_test shape:  (1560, 561)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDsF7ew5fx5r",
        "outputId": "11e7c471-69bb-4aa4-9d28-651d7e5d6e70"
      },
      "source": [
        "print (\"y_train shape: \",y_train.shape)\r\n",
        "print (\"y_test shape: \",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train shape:  (4067,)\n",
            "y_test shape:  (1560,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoKsb2Hey9g4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "7156e9e4-0380-4eda-f124-7d4cbefd582e"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "x_train_reshaped=np.reshape(X_train,(-1, 3, 561, 64))\r\n",
        "#x_test_reshaped=np.reshape(x_test,(10000, 28, 28))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-dcf005367788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train_reshaped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m561\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#x_test_reshaped=np.reshape(x_test,(10000, 28, 28))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    297\u001b[0m            [5, 6]])\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 9992 into shape (3,561,64)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SopHTsUcO2Or"
      },
      "source": [
        "verbose = 1\r\n",
        "epochs = 70\r\n",
        "batch_size = 40\r\n",
        "\r\n",
        "n_timesteps = X_train.shape[0]\r\n",
        "n_features = X_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSfgc6ogKT2l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLALmDDkXCA9",
        "outputId": "0f85848e-be54-4af4-97f0-9789dffe34b5"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"har_weights.h5\", monitor='val_acc', verbose=1, \r\n",
        "                             save_best_only=True, save_weights_only=False, mode='auto', period=1)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsKYYgxCksei",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "500fc84b-521e-4906-e85c-8835606e3f6c"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(batch_size,1,n_features)))\r\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding = 'same'))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "model.add(MaxPooling1D(pool_size=2))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(100, activation='relu'))\r\n",
        "model.add(Dense(3, activation='softmax'))\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv1d_2/conv1d/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_2/conv1d/Reshape, conv1d_2/conv1d/ExpandDims_1)' with input shapes: [?,1,1,561], [1,3,561,64].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-dc1b80c21c1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1018\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1148\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 605\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 605\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)\u001b[0m\n\u001b[1;32m   1905\u001b[0m           ),\n\u001b[1;32m   1906\u001b[0m           \u001b[0minner_rank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1907\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1908\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspatial_start_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msqueeze_batch_dims\u001b[0;34m(inp, op, inner_rank, name)\u001b[0m\n\u001b[1;32m    311\u001b[0m           inp, array_ops.concat(([-1], inner_shape), axis=-1))\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0mout_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0mout_inner_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_reshaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minner_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    971\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    974\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    748\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    590\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3534\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3535\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3536\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3537\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3538\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 2016\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv1d_2/conv1d/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_2/conv1d/Reshape, conv1d_2/conv1d/ExpandDims_1)' with input shapes: [?,1,1,561], [1,3,561,64]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UHNJByY6pCg",
        "outputId": "48451954-6a2b-41b5-c85d-67005f5ebbc9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 4065, 64)          107776    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 4065, 64)          12352     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4065, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 2032, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 130048)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               13004900  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 13,125,331\n",
            "Trainable params: 13,125,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "22YDb9Kll2Ev",
        "outputId": "feb4bd5d-f571-4699-9d31-0e9c5c297a79"
      },
      "source": [
        "# fit network\r\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \r\n",
        "                    epochs=epochs, batch_size=batch_size, callbacks = [checkpoint], verbose=verbose)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-a147e2afb98f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n\u001b[0;32m----> 3\u001b[0;31m                     epochs=epochs, batch_size=batch_size, callbacks = [checkpoint], verbose=verbose)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (None, 561)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Bj0vRCk_qQ"
      },
      "source": [
        "# evaluate model\r\n",
        "(loss, accuracy) = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\r\n",
        "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y_MV3qKPXyI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}